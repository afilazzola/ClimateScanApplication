library(tidyverse)
library(wordcloud)
invalid 'cex' value
## subset based on departemtn
dept.words <- subset(df.in, department==input$department)
## load text from Then and So
text_df <- data_frame(text=as.character(dept.words$Then),as.character(dept.words$So))
word.count <- text_df %>% unnest_tokens(word,text) %>%  dplyr::count(word, sort=T) ## count words
## list stopwords
stopwords <- c(stop_words$word, "risk","e.g.","e.g","due","increases","decreases","impacts","impact","lack","risks", "increase","increased","increasing","decrease","decreased","decreasing","lower","low","high","higher")
## remove stopwords
stop1 <- text_df %>% unnest_tokens(word,text) ## separate words into separate lines
stop2 <- stop1[!stop1$word %in% stopwords,] ## remove stop words
stop3 <- stop2 %>% dplyr::count(word, sort=T) ## sort words by frequency
df.in
str(df.in)
df.in[,"Future.risk.quant"] <- df.in[,"sum.future.quant"]
df.in[,"department"] <- paste(df.in[,"Department"],df.in[,"Division"], sep=":") ## creates a unique column that combines division and subidentifier
str(df.in)
dept.words <- subset(df.in, department=="CORP:Recreation & Culture")
dept.words
## load text from Then and So
text_df <- data_frame(text=as.character(dept.words$Then),as.character(dept.words$So))
word.count <- text_df %>% unnest_tokens(word,text) %>%  dplyr::count(word, sort=T) ## count words
## list stopwords
stopwords <- c(stop_words$word, "risk","e.g.","e.g","due","increases","decreases","impacts","impact","lack","risks", "increase","increased","increasing","decrease","decreased","decreasing","lower","low","high","higher")
## remove stopwords
stop1 <- text_df %>% unnest_tokens(word,text) ## separate words into separate lines
stop2 <- stop1[!stop1$word %in% stopwords,] ## remove stop words
stop3 <- stop2 %>% dplyr::count(word, sort=T) ## sort words by frequency
stop3
data.frame(stop3)
wordcloud(stop3$word, stop3$n, max.words=60, min.freq=1)
?wordcloud
dept.words <- subset(df.in, department==df.in$department[1])
dept.words <- subset(df.in, department==df.in$department[1])
## load text from Then and So
text_df <- data_frame(text=as.character(dept.words$Then),as.character(dept.words$So))
word.count <- text_df %>% unnest_tokens(word,text) %>%  dplyr::count(word, sort=T) ## count words
## list stopwords
stopwords <- c(stop_words$word, "risk","e.g.","e.g","due","increases","decreases","impacts","impact","lack","risks", "increase","increased","increasing","decrease","decreased","decreasing","lower","low","high","higher")
## remove stopwords
stop1 <- text_df %>% unnest_tokens(word,text) ## separate words into separate lines
stop2 <- stop1[!stop1$word %in% stopwords,] ## remove stop words
stop3 <- stop2 %>% dplyr::count(word, sort=T) ## sort words by frequency
wordcloud(stop3$word, stop3$n, max.words=60, min.freq=1)
data.frame(stop3)
dept.words <- subset(df.in, department==df.in$department[2])
## load text from Then and So
text_df <- data_frame(text=as.character(dept.words$Then),as.character(dept.words$So))
word.count <- text_df %>% unnest_tokens(word,text) %>%  dplyr::count(word, sort=T) ## count words
## list stopwords
stopwords <- c(stop_words$word, "risk","e.g.","e.g","due","increases","decreases","impacts","impact","lack","risks", "increase","increased","increasing","decrease","decreased","decreasing","lower","low","high","higher")
## remove stopwords
stop1 <- text_df %>% unnest_tokens(word,text) ## separate words into separate lines
stop2 <- stop1[!stop1$word %in% stopwords,] ## remove stop words
stop3 <- stop2 %>% dplyr::count(word, sort=T) ## sort words by frequency
wordcloud(stop3$word, stop3$n, max.words=60, min.freq=1)
data.frame(stop3)
dept.words <- subset(df.in, department==df.in$department[3])
## load text from Then and So
text_df <- data_frame(text=as.character(dept.words$Then),as.character(dept.words$So))
word.count <- text_df %>% unnest_tokens(word,text) %>%  dplyr::count(word, sort=T) ## count words
## list stopwords
stopwords <- c(stop_words$word, "risk","e.g.","e.g","due","increases","decreases","impacts","impact","lack","risks", "increase","increased","increasing","decrease","decreased","decreasing","lower","low","high","higher")
## remove stopwords
stop1 <- text_df %>% unnest_tokens(word,text) ## separate words into separate lines
stop2 <- stop1[!stop1$word %in% stopwords,] ## remove stop words
stop3 <- stop2 %>% dplyr::count(word, sort=T) ## sort words by frequency
wordcloud(stop3$word, stop3$n, max.words=60, min.freq=1)
data.frame(stop3)
length(df.in$department)
unique(df.in$department)
is.na(data.frame(stop3))
sum(is.na(data.frame(stop3)))
stop3[1,1] <- "NAN"
sum(is.na(data.frame(stop3)))
stop3[1,1] <- "NaN"
sum(is.na(data.frame(stop3)))
stop3[1,1] <- "NA"
sum(is.na(data.frame(stop3)))
stop3
data.frame(stop3)
dept.words <- subset(df.in, department==unique(df.in$department)[1])
## load text from Then and So
text_df <- data_frame(text=as.character(dept.words$Then),as.character(dept.words$So))
word.count <- text_df %>% unnest_tokens(word,text) %>%  dplyr::count(word, sort=T) ## count words
## list stopwords
stopwords <- c(stop_words$word, "risk","e.g.","e.g","due","increases","decreases","impacts","impact","lack","risks", "increase","increased","increasing","decrease","decreased","decreasing","lower","low","high","higher")
## remove stopwords
stop1 <- text_df %>% unnest_tokens(word,text) ## separate words into separate lines
stop2 <- stop1[!stop1$word %in% stopwords,] ## remove stop words
stop3 <- stop2 %>% dplyr::count(word, sort=T) ## sort words by frequency
wordcloud(stop3$word, stop3$n, max.words=60, min.freq=1)
data.frame(stop3)
dept.words <- subset(df.in, department==unique(df.in$department)[2])
## load text from Then and So
text_df <- data_frame(text=as.character(dept.words$Then),as.character(dept.words$So))
word.count <- text_df %>% unnest_tokens(word,text) %>%  dplyr::count(word, sort=T) ## count words
## list stopwords
stopwords <- c(stop_words$word, "risk","e.g.","e.g","due","increases","decreases","impacts","impact","lack","risks", "increase","increased","increasing","decrease","decreased","decreasing","lower","low","high","higher")
## remove stopwords
stop1 <- text_df %>% unnest_tokens(word,text) ## separate words into separate lines
stop2 <- stop1[!stop1$word %in% stopwords,] ## remove stop words
stop3 <- stop2 %>% dplyr::count(word, sort=T) ## sort words by frequency
wordcloud(stop3$word, stop3$n, max.words=60, min.freq=1)
data.frame(stop3)
dept.words <- subset(df.in, department==unique(df.in$department)[3])
## load text from Then and So
text_df <- data_frame(text=as.character(dept.words$Then),as.character(dept.words$So))
word.count <- text_df %>% unnest_tokens(word,text) %>%  dplyr::count(word, sort=T) ## count words
## list stopwords
stopwords <- c(stop_words$word, "risk","e.g.","e.g","due","increases","decreases","impacts","impact","lack","risks", "increase","increased","increasing","decrease","decreased","decreasing","lower","low","high","higher")
## remove stopwords
stop1 <- text_df %>% unnest_tokens(word,text) ## separate words into separate lines
stop2 <- stop1[!stop1$word %in% stopwords,] ## remove stop words
stop3 <- stop2 %>% dplyr::count(word, sort=T) ## sort words by frequency
wordcloud(stop3$word, stop3$n, max.words=60, min.freq=1)
data.frame(stop3)
dept.words <- subset(df.in, department==unique(df.in$department)[4])
## load text from Then and So
text_df <- data_frame(text=as.character(dept.words$Then),as.character(dept.words$So))
word.count <- text_df %>% unnest_tokens(word,text) %>%  dplyr::count(word, sort=T) ## count words
## list stopwords
stopwords <- c(stop_words$word, "risk","e.g.","e.g","due","increases","decreases","impacts","impact","lack","risks", "increase","increased","increasing","decrease","decreased","decreasing","lower","low","high","higher")
## remove stopwords
stop1 <- text_df %>% unnest_tokens(word,text) ## separate words into separate lines
stop2 <- stop1[!stop1$word %in% stopwords,] ## remove stop words
stop3 <- stop2 %>% dplyr::count(word, sort=T) ## sort words by frequency
wordcloud(stop3$word, stop3$n, max.words=60, min.freq=1)
data.frame(stop3)
wordcloud(stop3$word, stop3$n, max.words=60, min.freq=1)
dept.words <- subset(df.in, department==unique(df.in$department)[5])
## load text from Then and So
text_df <- data_frame(text=as.character(dept.words$Then),as.character(dept.words$So))
word.count <- text_df %>% unnest_tokens(word,text) %>%  dplyr::count(word, sort=T) ## count words
## list stopwords
stopwords <- c(stop_words$word, "risk","e.g.","e.g","due","increases","decreases","impacts","impact","lack","risks", "increase","increased","increasing","decrease","decreased","decreasing","lower","low","high","higher")
## remove stopwords
stop1 <- text_df %>% unnest_tokens(word,text) ## separate words into separate lines
stop2 <- stop1[!stop1$word %in% stopwords,] ## remove stop words
stop3 <- stop2 %>% dplyr::count(word, sort=T) ## sort words by frequency
wordcloud(stop3$word, stop3$n, max.words=60, min.freq=1)
data.frame(stop3)
dept.words <- subset(df.in, department==unique(df.in$department)[6])
## load text from Then and So
text_df <- data_frame(text=as.character(dept.words$Then),as.character(dept.words$So))
word.count <- text_df %>% unnest_tokens(word,text) %>%  dplyr::count(word, sort=T) ## count words
## list stopwords
stopwords <- c(stop_words$word, "risk","e.g.","e.g","due","increases","decreases","impacts","impact","lack","risks", "increase","increased","increasing","decrease","decreased","decreasing","lower","low","high","higher")
## remove stopwords
stop1 <- text_df %>% unnest_tokens(word,text) ## separate words into separate lines
stop2 <- stop1[!stop1$word %in% stopwords,] ## remove stop words
stop3 <- stop2 %>% dplyr::count(word, sort=T) ## sort words by frequency
wordcloud(stop3$word, stop3$n, max.words=60, min.freq=1)
data.frame(stop3)
dept.words <- subset(df.in, department==unique(df.in$department)[7])
## load text from Then and So
text_df <- data_frame(text=as.character(dept.words$Then),as.character(dept.words$So))
word.count <- text_df %>% unnest_tokens(word,text) %>%  dplyr::count(word, sort=T) ## count words
## list stopwords
stopwords <- c(stop_words$word, "risk","e.g.","e.g","due","increases","decreases","impacts","impact","lack","risks", "increase","increased","increasing","decrease","decreased","decreasing","lower","low","high","higher")
## remove stopwords
stop1 <- text_df %>% unnest_tokens(word,text) ## separate words into separate lines
stop2 <- stop1[!stop1$word %in% stopwords,] ## remove stop words
stop3 <- stop2 %>% dplyr::count(word, sort=T) ## sort words by frequency
wordcloud(stop3$word, stop3$n, max.words=60, min.freq=1)
data.frame(stop3)
dept.words <- subset(df.in, department==unique(df.in$department)[8])
## load text from Then and So
text_df <- data_frame(text=as.character(dept.words$Then),as.character(dept.words$So))
word.count <- text_df %>% unnest_tokens(word,text) %>%  dplyr::count(word, sort=T) ## count words
## list stopwords
stopwords <- c(stop_words$word, "risk","e.g.","e.g","due","increases","decreases","impacts","impact","lack","risks", "increase","increased","increasing","decrease","decreased","decreasing","lower","low","high","higher")
## remove stopwords
stop1 <- text_df %>% unnest_tokens(word,text) ## separate words into separate lines
stop2 <- stop1[!stop1$word %in% stopwords,] ## remove stop words
stop3 <- stop2 %>% dplyr::count(word, sort=T) ## sort words by frequency
wordcloud(stop3$word, stop3$n, max.words=60, min.freq=1)
data.frame(stop3)
dept.words <- subset(df.in, department==unique(df.in$department)[9])
## load text from Then and So
text_df <- data_frame(text=as.character(dept.words$Then),as.character(dept.words$So))
word.count <- text_df %>% unnest_tokens(word,text) %>%  dplyr::count(word, sort=T) ## count words
## list stopwords
stopwords <- c(stop_words$word, "risk","e.g.","e.g","due","increases","decreases","impacts","impact","lack","risks", "increase","increased","increasing","decrease","decreased","decreasing","lower","low","high","higher")
## remove stopwords
stop1 <- text_df %>% unnest_tokens(word,text) ## separate words into separate lines
stop2 <- stop1[!stop1$word %in% stopwords,] ## remove stop words
stop3 <- stop2 %>% dplyr::count(word, sort=T) ## sort words by frequency
wordcloud(stop3$word, stop3$n, max.words=60, min.freq=1)
data.frame(stop3)
dept.words <- subset(df.in, department==unique(df.in$department)[10])
## load text from Then and So
text_df <- data_frame(text=as.character(dept.words$Then),as.character(dept.words$So))
word.count <- text_df %>% unnest_tokens(word,text) %>%  dplyr::count(word, sort=T) ## count words
## list stopwords
stopwords <- c(stop_words$word, "risk","e.g.","e.g","due","increases","decreases","impacts","impact","lack","risks", "increase","increased","increasing","decrease","decreased","decreasing","lower","low","high","higher")
## remove stopwords
stop1 <- text_df %>% unnest_tokens(word,text) ## separate words into separate lines
stop2 <- stop1[!stop1$word %in% stopwords,] ## remove stop words
stop3 <- stop2 %>% dplyr::count(word, sort=T) ## sort words by frequency
wordcloud(stop3$word, stop3$n, max.words=60, min.freq=1)
data.frame(stop3)
dept.words <- subset(df.in, department==unique(df.in$department)[11])
## load text from Then and So
text_df <- data_frame(text=as.character(dept.words$Then),as.character(dept.words$So))
word.count <- text_df %>% unnest_tokens(word,text) %>%  dplyr::count(word, sort=T) ## count words
## list stopwords
stopwords <- c(stop_words$word, "risk","e.g.","e.g","due","increases","decreases","impacts","impact","lack","risks", "increase","increased","increasing","decrease","decreased","decreasing","lower","low","high","higher")
## remove stopwords
stop1 <- text_df %>% unnest_tokens(word,text) ## separate words into separate lines
stop2 <- stop1[!stop1$word %in% stopwords,] ## remove stop words
stop3 <- stop2 %>% dplyr::count(word, sort=T) ## sort words by frequency
wordcloud(stop3$word, stop3$n, max.words=60, min.freq=1)
data.frame(stop3)
dept.words <- subset(df.in, department==unique(df.in$department)[12])
## load text from Then and So
text_df <- data_frame(text=as.character(dept.words$Then),as.character(dept.words$So))
word.count <- text_df %>% unnest_tokens(word,text) %>%  dplyr::count(word, sort=T) ## count words
## list stopwords
stopwords <- c(stop_words$word, "risk","e.g.","e.g","due","increases","decreases","impacts","impact","lack","risks", "increase","increased","increasing","decrease","decreased","decreasing","lower","low","high","higher")
## remove stopwords
stop1 <- text_df %>% unnest_tokens(word,text) ## separate words into separate lines
stop2 <- stop1[!stop1$word %in% stopwords,] ## remove stop words
stop3 <- stop2 %>% dplyr::count(word, sort=T) ## sort words by frequency
wordcloud(stop3$word, stop3$n, max.words=60, min.freq=1)
data.frame(stop3)
dept.words <- subset(df.in, department==unique(df.in$department)[13])
## load text from Then and So
text_df <- data_frame(text=as.character(dept.words$Then),as.character(dept.words$So))
word.count <- text_df %>% unnest_tokens(word,text) %>%  dplyr::count(word, sort=T) ## count words
## list stopwords
stopwords <- c(stop_words$word, "risk","e.g.","e.g","due","increases","decreases","impacts","impact","lack","risks", "increase","increased","increasing","decrease","decreased","decreasing","lower","low","high","higher")
## remove stopwords
stop1 <- text_df %>% unnest_tokens(word,text) ## separate words into separate lines
stop2 <- stop1[!stop1$word %in% stopwords,] ## remove stop words
stop3 <- stop2 %>% dplyr::count(word, sort=T) ## sort words by frequency
wordcloud(stop3$word, stop3$n, max.words=60, min.freq=1)
data.frame(stop3)
dept.words <- subset(df.in, department==unique(df.in$department)[15])
## load text from Then and So
text_df <- data_frame(text=as.character(dept.words$Then),as.character(dept.words$So))
word.count <- text_df %>% unnest_tokens(word,text) %>%  dplyr::count(word, sort=T) ## count words
## list stopwords
stopwords <- c(stop_words$word, "risk","e.g.","e.g","due","increases","decreases","impacts","impact","lack","risks", "increase","increased","increasing","decrease","decreased","decreasing","lower","low","high","higher")
## remove stopwords
stop1 <- text_df %>% unnest_tokens(word,text) ## separate words into separate lines
stop2 <- stop1[!stop1$word %in% stopwords,] ## remove stop words
stop3 <- stop2 %>% dplyr::count(word, sort=T) ## sort words by frequency
wordcloud(stop3$word, stop3$n, max.words=60, min.freq=1)
data.frame(stop3)
dept.words <- subset(df.in, department==unique(df.in$department)[16])
## load text from Then and So
text_df <- data_frame(text=as.character(dept.words$Then),as.character(dept.words$So))
word.count <- text_df %>% unnest_tokens(word,text) %>%  dplyr::count(word, sort=T) ## count words
## list stopwords
stopwords <- c(stop_words$word, "risk","e.g.","e.g","due","increases","decreases","impacts","impact","lack","risks", "increase","increased","increasing","decrease","decreased","decreasing","lower","low","high","higher")
## remove stopwords
stop1 <- text_df %>% unnest_tokens(word,text) ## separate words into separate lines
stop2 <- stop1[!stop1$word %in% stopwords,] ## remove stop words
stop3 <- stop2 %>% dplyr::count(word, sort=T) ## sort words by frequency
wordcloud(stop3$word, stop3$n, max.words=60, min.freq=1)
data.frame(stop3)
dept.words <- subset(df.in, department==unique(df.in$department)[17])
## load text from Then and So
text_df <- data_frame(text=as.character(dept.words$Then),as.character(dept.words$So))
word.count <- text_df %>% unnest_tokens(word,text) %>%  dplyr::count(word, sort=T) ## count words
## list stopwords
stopwords <- c(stop_words$word, "risk","e.g.","e.g","due","increases","decreases","impacts","impact","lack","risks", "increase","increased","increasing","decrease","decreased","decreasing","lower","low","high","higher")
## remove stopwords
stop1 <- text_df %>% unnest_tokens(word,text) ## separate words into separate lines
stop2 <- stop1[!stop1$word %in% stopwords,] ## remove stop words
stop3 <- stop2 %>% dplyr::count(word, sort=T) ## sort words by frequency
wordcloud(stop3$word, stop3$n, max.words=60, min.freq=1)
data.frame(stop3)
dept.words <- subset(df.in, department==unique(df.in$department)[18])
## load text from Then and So
text_df <- data_frame(text=as.character(dept.words$Then),as.character(dept.words$So))
word.count <- text_df %>% unnest_tokens(word,text) %>%  dplyr::count(word, sort=T) ## count words
## list stopwords
stopwords <- c(stop_words$word, "risk","e.g.","e.g","due","increases","decreases","impacts","impact","lack","risks", "increase","increased","increasing","decrease","decreased","decreasing","lower","low","high","higher")
## remove stopwords
stop1 <- text_df %>% unnest_tokens(word,text) ## separate words into separate lines
stop2 <- stop1[!stop1$word %in% stopwords,] ## remove stop words
stop3 <- stop2 %>% dplyr::count(word, sort=T) ## sort words by frequency
wordcloud(stop3$word, stop3$n, max.words=60, min.freq=1)
data.frame(stop3)
dept.words <- subset(df.in, department==unique(df.in$department)[19])
## load text from Then and So
text_df <- data_frame(text=as.character(dept.words$Then),as.character(dept.words$So))
word.count <- text_df %>% unnest_tokens(word,text) %>%  dplyr::count(word, sort=T) ## count words
## list stopwords
stopwords <- c(stop_words$word, "risk","e.g.","e.g","due","increases","decreases","impacts","impact","lack","risks", "increase","increased","increasing","decrease","decreased","decreasing","lower","low","high","higher")
## remove stopwords
stop1 <- text_df %>% unnest_tokens(word,text) ## separate words into separate lines
stop2 <- stop1[!stop1$word %in% stopwords,] ## remove stop words
stop3 <- stop2 %>% dplyr::count(word, sort=T) ## sort words by frequency
wordcloud(stop3$word, stop3$n, max.words=60, min.freq=1)
data.frame(stop3)
warnings()
wordcloud(stop3$word, stop3$n, max.words=60, min.freq=2)
wordcloud(stop3$word, stop3$n, max.words=60, min.freq=2)
data.frame(stop3)
dept.words <- subset(df.in, department==unique(df.in$department)[20])
## load text from Then and So
text_df <- data_frame(text=as.character(dept.words$Then),as.character(dept.words$So))
word.count <- text_df %>% unnest_tokens(word,text) %>%  dplyr::count(word, sort=T) ## count words
## list stopwords
stopwords <- c(stop_words$word, "risk","e.g.","e.g","due","increases","decreases","impacts","impact","lack","risks", "increase","increased","increasing","decrease","decreased","decreasing","lower","low","high","higher")
## remove stopwords
stop1 <- text_df %>% unnest_tokens(word,text) ## separate words into separate lines
stop2 <- stop1[!stop1$word %in% stopwords,] ## remove stop words
stop3 <- stop2 %>% dplyr::count(word, sort=T) ## sort words by frequency
wordcloud(stop3$word, stop3$n, max.words=60, min.freq=2)
data.frame(stop3)
dept.words <- subset(df.in, department==unique(df.in$department)[21])
## load text from Then and So
text_df <- data_frame(text=as.character(dept.words$Then),as.character(dept.words$So))
word.count <- text_df %>% unnest_tokens(word,text) %>%  dplyr::count(word, sort=T) ## count words
## list stopwords
stopwords <- c(stop_words$word, "risk","e.g.","e.g","due","increases","decreases","impacts","impact","lack","risks", "increase","increased","increasing","decrease","decreased","decreasing","lower","low","high","higher")
## remove stopwords
stop1 <- text_df %>% unnest_tokens(word,text) ## separate words into separate lines
stop2 <- stop1[!stop1$word %in% stopwords,] ## remove stop words
stop3 <- stop2 %>% dplyr::count(word, sort=T) ## sort words by frequency
wordcloud(stop3$word, stop3$n, max.words=60, min.freq=2)
data.frame(stop3)
dept.words <- subset(df.in, department==unique(df.in$department)[22])
## load text from Then and So
text_df <- data_frame(text=as.character(dept.words$Then),as.character(dept.words$So))
word.count <- text_df %>% unnest_tokens(word,text) %>%  dplyr::count(word, sort=T) ## count words
## list stopwords
stopwords <- c(stop_words$word, "risk","e.g.","e.g","due","increases","decreases","impacts","impact","lack","risks", "increase","increased","increasing","decrease","decreased","decreasing","lower","low","high","higher")
## remove stopwords
stop1 <- text_df %>% unnest_tokens(word,text) ## separate words into separate lines
stop2 <- stop1[!stop1$word %in% stopwords,] ## remove stop words
stop3 <- stop2 %>% dplyr::count(word, sort=T) ## sort words by frequency
wordcloud(stop3$word, stop3$n, max.words=60, min.freq=2)
data.frame(stop3)
dept.words <- subset(df.in, department==unique(df.in$department)[23])
## load text from Then and So
text_df <- data_frame(text=as.character(dept.words$Then),as.character(dept.words$So))
word.count <- text_df %>% unnest_tokens(word,text) %>%  dplyr::count(word, sort=T) ## count words
## list stopwords
stopwords <- c(stop_words$word, "risk","e.g.","e.g","due","increases","decreases","impacts","impact","lack","risks", "increase","increased","increasing","decrease","decreased","decreasing","lower","low","high","higher")
## remove stopwords
stop1 <- text_df %>% unnest_tokens(word,text) ## separate words into separate lines
stop2 <- stop1[!stop1$word %in% stopwords,] ## remove stop words
stop3 <- stop2 %>% dplyr::count(word, sort=T) ## sort words by frequency
wordcloud(stop3$word, stop3$n, max.words=60, min.freq=2)
data.frame(stop3)
dept.words <- subset(df.in, department==unique(df.in$department)[24])
## load text from Then and So
text_df <- data_frame(text=as.character(dept.words$Then),as.character(dept.words$So))
word.count <- text_df %>% unnest_tokens(word,text) %>%  dplyr::count(word, sort=T) ## count words
## list stopwords
stopwords <- c(stop_words$word, "risk","e.g.","e.g","due","increases","decreases","impacts","impact","lack","risks", "increase","increased","increasing","decrease","decreased","decreasing","lower","low","high","higher")
## remove stopwords
stop1 <- text_df %>% unnest_tokens(word,text) ## separate words into separate lines
stop2 <- stop1[!stop1$word %in% stopwords,] ## remove stop words
stop3 <- stop2 %>% dplyr::count(word, sort=T) ## sort words by frequency
wordcloud(stop3$word, stop3$n, max.words=60, min.freq=2)
data.frame(stop3)
unique(df.in$department)[24]
runApp()
runApp()
runApp()
df.in
df.in$department
unique(df.in$department)
class(unique(df.in$department))
department <- as.vector(unique(df.in$department))
department
class(department)
runApp()
runApp()
runApp()
df.in
dept.options <- as.vector(unique(df.in$department))
dept.options
runApp()
runApp()
runApp()
runApp()
runApp()
library(rsconnect)
deployApp()
runApp()
runApp()
runApp()
runApp()
shiny::runApp()
runApp()
<<<<<<< HEAD
runApp()
runApp()
runApp()
df
test
test <- read.csv(C:\\Data\\PhD - 10th Year\\richmondhill.climatescan\\richmondhill.summed.csv)
test <- read.csv("C:\\Data\\PhD - 10th Year\\richmondhill.climatescan\\richmondhill.summed.csv)
test <- read.csv("C:\\Data\\PhD - 10th Year\\richmondhill.climatescan\\richmondhill.summed.csv")
str(test)
df <- test
df[,"department"] <- paste(df[,"Division"],df[,"Sub.Identifier"], sep=":")
depts <- unique(df$department)
df
str(df)
depts
intval2 <- data.frame()
for(j in 1:length(depts)){
intval <- data.frame() ## empty row dataframe
for(i in 1:length(depts)){
dept.1 <- subset(df, department==depts[j], select=c("If","Then.simplified")) ## select risks from department "j"
dept.1 <- paste(dept.1$If,dept.1$Then.simplified) ## combine into 1 column
dept.i <- subset(df, department==depts[i], select=c("If","Then.simplified")) ## select risks from department "i"
dept.i <- paste(dept.i$If,dept.i$Then.simplified) ## combine into 1 column
val <- data.frame(dept=length(intersect(dept.1,dept.i))) ## count number of duplicates between two departments
rownames(val) <- paste(depts[i]) # attach department "i" name
intval <- rbind(intval,val) ## attach to empty dataframe
}
colnames(intval) <- paste(depts[j]) ##attach department "j" name
intval2 <- cbind.fill(intval2,intval) ## attach completed row into empty dataframe
}
intval2
str(intval2)
source("cbind.r")
for(j in 1:length(depts)){
intval <- data.frame() ## empty row dataframe
for(i in 1:length(depts)){
dept.1 <- subset(df, department==depts[j], select=c("If","Then.simplified")) ## select risks from department "j"
dept.1 <- paste(dept.1$If,dept.1$Then.simplified) ## combine into 1 column
dept.i <- subset(df, department==depts[i], select=c("If","Then.simplified")) ## select risks from department "i"
dept.i <- paste(dept.i$If,dept.i$Then.simplified) ## combine into 1 column
val <- data.frame(dept=length(intersect(dept.1,dept.i))) ## count number of duplicates between two departments
rownames(val) <- paste(depts[i]) # attach department "i" name
intval <- rbind(intval,val) ## attach to empty dataframe
}
colnames(intval) <- paste(depts[j]) ##attach department "j" name
intval2 <- cbind.fill(intval2,intval) ## attach completed row into empty dataframe
}
intval2
str(intval2)
str(intval2)
str(df)
source("cbind.r")
intval2 <- data.frame()
for(j in 1:length(depts)){
intval <- data.frame() ## empty row dataframe
for(i in 1:length(depts)){
dept.1 <- subset(df, department==depts[j], select=c("If","Then.simplified")) ## select risks from department "j"
dept.1 <- paste(dept.1$If,dept.1$Then.simplified) ## combine into 1 column
dept.i <- subset(df, department==depts[i], select=c("If","Then.simplified")) ## select risks from department "i"
dept.i <- paste(dept.i$If,dept.i$Then.simplified) ## combine into 1 column
val <- data.frame(dept=length(intersect(dept.1,dept.i))) ## count number of duplicates between two departments
rownames(val) <- paste(depts[i]) # attach department "i" name
intval <- rbind(intval,val) ## attach to empty dataframe
}
colnames(intval) <- paste(depts[j]) ##attach department "j" name
intval2 <- cbind.fill(intval2,intval) ## attach completed row into empty dataframe
}
corrplot(intval2, method = "square")
intval2
str(intval2)
intval <- data.frame() ## empty row dataframe
for(i in 1:length(depts)){
dept.1 <- subset(df, department==depts[j], select=c("If","Then.simplified")) ## select risks from department "j"
dept.1 <- paste(dept.1$If,dept.1$Then.simplified) ## combine into 1 column
dept.i <- subset(df, department==depts[i], select=c("If","Then.simplified")) ## select risks from department "i"
dept.i <- paste(dept.i$If,dept.i$Then.simplified) ## combine into 1 column
val <- data.frame(dept=length(intersect(dept.1,dept.i))) ## count number of duplicates between two departments
rownames(val) <- paste(depts[i]) # attach department "i" name
intval <- rbind(intval,val) ## attach to empty dataframe
}
intval
str(intval)
colnames(intval) <- paste(depts[j])
intval
i
j
depts[i]
intval2 <- data.frame()
intval2 <- cbind.fill(intval2,intval)
intval2
str(intval2)
class(intval2)
class(intval)
intval2 <- data.frame()
intval2
intval2 <- cbind(intval2,intval)
intval2[,j] <- intval ## attach completed row into empty dataframe
intval2 <- data.frame()
intval2[,j] <- intval ## attach completed row into empty dataframe
intval
intval2
cbind.fill <- function(...){
nm <- list(...)
nm <- lapply(nm, as.matrix)
n <- max(sapply(nm, nrow))
do.call(cbind, lapply(nm, function (x)
rbind(x, matrix(, n-nrow(x), ncol(x)))))
}
intval2 <- cbind.fill(intval2,intval)
str(intval2)
class(intval2)
intval2[,j] <- intval ## attach completed row into empty dataframe
intval2 <- cbind.fill(intval2,intval)
class(intval2)
str(intval2)
intval2 <- data.frame()
intval2
intval
bind_cols(intval, intval2)
intval2 <- data.frame()
for(j in 1:length(depts)){
intval <- data.frame() ## empty row dataframe
for(i in 1:length(depts)){
dept.1 <- subset(df, department==depts[j], select=c("If","Then.simplified")) ## select risks from department "j"
dept.1 <- paste(dept.1$If,dept.1$Then.simplified) ## combine into 1 column
dept.i <- subset(df, department==depts[i], select=c("If","Then.simplified")) ## select risks from department "i"
dept.i <- paste(dept.i$If,dept.i$Then.simplified) ## combine into 1 column
val <- data.frame(dept=length(intersect(dept.1,dept.i))) ## count number of duplicates between two departments
rownames(val) <- paste(depts[i]) # attach department "i" name
intval <- rbind(intval,val) ## attach to empty dataframe
}
colnames(intval) <- paste(depts[j]) ##attach department "j" name
intval2 <- bind_cols(intval2, intval) ## attach completed row into empty dataframe
}
corrplot(intval2, method = "square")
str(intval2)
intval2 <- data.frame()
for(j in 1:length(depts)){
intval <- data.frame() ## empty row dataframe
for(i in 1:length(depts)){
dept.1 <- subset(df, department==depts[j], select=c("If","Then.simplified")) ## select risks from department "j"
dept.1 <- paste(dept.1$If,dept.1$Then.simplified) ## combine into 1 column
dept.i <- subset(df, department==depts[i], select=c("If","Then.simplified")) ## select risks from department "i"
dept.i <- paste(dept.i$If,dept.i$Then.simplified) ## combine into 1 column
val <- data.frame(dept=length(intersect(dept.1,dept.i))) ## count number of duplicates between two departments
rownames(val) <- paste(depts[i]) # attach department "i" name
intval <- rbind(intval,val) ## attach to empty dataframe
}
colnames(intval) <- paste(depts[j]) ##attach department "j" name
intval2 <- bind_cols(intval2, intval) ## attach completed row into empty dataframe
}
intval2
intval
intval2 <- bind_cols(intval2, intval)
bind_cols(intval2, intval)
intval2 <- combine(intval2, intval) ## attach completed row into empty dataframe
intval2 <- data.frame(ncol=26,nrow=26)
for(j in 1:length(depts)){
intval <- data.frame() ## empty row dataframe
for(i in 1:length(depts)){
dept.1 <- subset(df, department==depts[j], select=c("If","Then.simplified")) ## select risks from department "j"
dept.1 <- paste(dept.1$If,dept.1$Then.simplified) ## combine into 1 column
dept.i <- subset(df, department==depts[i], select=c("If","Then.simplified")) ## select risks from department "i"
dept.i <- paste(dept.i$If,dept.i$Then.simplified) ## combine into 1 column
val <- data.frame(dept=length(intersect(dept.1,dept.i))) ## count number of duplicates between two departments
rownames(val) <- paste(depts[i]) # attach department "i" name
intval <- rbind(intval,val) ## attach to empty dataframe
}
colnames(intval) <- paste(depts[j]) ##attach department "j" name
intval2 <- cbind(intval2, intval) ## attach completed row into empty dataframe
}
str(intval2)
corrplot(intval2, method = "square")
class(intval2)
intval2 <- data.frame(matrix(ncol=26,nrow=26))
for(j in 1:length(depts)){
intval <- data.frame() ## empty row dataframe
for(i in 1:length(depts)){
dept.1 <- subset(df, department==depts[j], select=c("If","Then.simplified")) ## select risks from department "j"
dept.1 <- paste(dept.1$If,dept.1$Then.simplified) ## combine into 1 column
dept.i <- subset(df, department==depts[i], select=c("If","Then.simplified")) ## select risks from department "i"
dept.i <- paste(dept.i$If,dept.i$Then.simplified) ## combine into 1 column
val <- data.frame(dept=length(intersect(dept.1,dept.i))) ## count number of duplicates between two departments
rownames(val) <- paste(depts[i]) # attach department "i" name
intval <- rbind(intval,val) ## attach to empty dataframe
}
colnames(intval) <- paste(depts[j]) ##attach department "j" name
intval2 <- cbind(intval2, intval) ## attach completed row into empty dataframe
}
str(intval2)
intval2 <- data.frame(matrix(ncol=26,nrow=26))
for(j in 1:length(depts)){
intval <- data.frame() ## empty row dataframe
for(i in 1:length(depts)){
dept.1 <- subset(df, department==depts[j], select=c("If","Then.simplified")) ## select risks from department "j"
dept.1 <- paste(dept.1$If,dept.1$Then.simplified) ## combine into 1 column
dept.i <- subset(df, department==depts[i], select=c("If","Then.simplified")) ## select risks from department "i"
dept.i <- paste(dept.i$If,dept.i$Then.simplified) ## combine into 1 column
val <- data.frame(dept=length(intersect(dept.1,dept.i))) ## count number of duplicates between two departments
rownames(val) <- paste(depts[i]) # attach department "i" name
intval <- rbind(intval,val) ## attach to empty dataframe
}
intval2[,j] <- intval ## attach completed row into empty dataframe
colnames(intval2)[j] <- paste(depts[j]) ##attach department "j" name
}
str(intval2)
corrplot(intval2, method = "square")
class(intval2)
str(intval2)
cor(intval2)
corrplot(cor(intval2), method = "square")
class(cor(intval2))
corrplot(matrix(intval2), method = "square")
matrix(intval2)
corrplot(intval2, method = "square")
class(intval2)
intval2
corrplot(as.matrix(intval2), method = "square")
as.matrix(intval2)
cordat <- gather(intval, dept1, dept2, 1:ncol(intval))
str(cordat)
library(reshape2)
cordata <- melt(intval2)
cordat
heat(cordat)
heat(cordata)
head(cordata)
cordat[,"dept"] <- rownames(intval2)
cordat
intval2[,"dept"] <- rownames(intval2)
intval2
intval2 <- data.frame(matrix(ncol=26,nrow=26))
for(j in 1:length(depts)){
intval <- data.frame() ## empty row dataframe
for(i in 1:length(depts)){
dept.1 <- subset(df, department==depts[j], select=c("If","Then.simplified")) ## select risks from department "j"
dept.1 <- paste(dept.1$If,dept.1$Then.simplified) ## combine into 1 column
dept.i <- subset(df, department==depts[i], select=c("If","Then.simplified")) ## select risks from department "i"
dept.i <- paste(dept.i$If,dept.i$Then.simplified) ## combine into 1 column
val <- data.frame(dept=length(intersect(dept.1,dept.i))) ## count number of duplicates between two departments
rownames(val) <- paste(depts[i]) # attach department "i" name
intval <- rbind(intval,val) ## attach to empty dataframe
}
intval2[,j] <- intval ## attach completed row into empty dataframe
colnames(intval2)[j] <- paste(depts[j]) ##attach department "j" name
}
str(intval2)
intval2
intval2[,"dept"] <- colnames(intval2)
intval2
cordata <- gather(intval2, dept, value, 1:ncol(intval2)-1)
cordata <- gather(intval2, dept, value, 1:(ncol(intval2)-1))
cordata
str(cordata)
26*26
26**26
26**2
intval2 <- data.frame(matrix(ncol=26,nrow=26))
for(j in 1:length(depts)){
intval <- data.frame() ## empty row dataframe
for(i in 1:length(depts)){
dept.1 <- subset(df, department==depts[j], select=c("If","Then.simplified")) ## select risks from department "j"
dept.1 <- paste(dept.1$If,dept.1$Then.simplified) ## combine into 1 column
dept.i <- subset(df, department==depts[i], select=c("If","Then.simplified")) ## select risks from department "i"
dept.i <- paste(dept.i$If,dept.i$Then.simplified) ## combine into 1 column
val <- data.frame(dept=length(intersect(dept.1,dept.i))) ## count number of duplicates between two departments
rownames(val) <- paste(depts[i]) # attach department "i" name
intval <- rbind(intval,val) ## attach to empty dataframe
}
intval2[,j] <- intval ## attach completed row into empty dataframe
colnames(intval2)[j] <- paste(depts[j]) ##attach department "j" name
}
intval2[,"dept1"] <- colnames(intval2)
cordata <- gather(intval2, dept2, value, 1:(ncol(intval2)-1))
ggplot(data = cordata, aes(x=dept1, y=dept2, fill=value)) +
geom_tile()
depts <- unique(df$Division.combined)
intval2 <- data.frame(matrix(ncol=26,nrow=26))
for(j in 1:length(depts)){
intval <- data.frame() ## empty row dataframe
for(i in 1:length(depts)){
dept.1 <- subset(df, department==depts[j], select=c("If","Then.simplified")) ## select risks from department "j"
dept.1 <- paste(dept.1$If,dept.1$Then.simplified) ## combine into 1 column
dept.i <- subset(df, department==depts[i], select=c("If","Then.simplified")) ## select risks from department "i"
dept.i <- paste(dept.i$If,dept.i$Then.simplified) ## combine into 1 column
val <- data.frame(dept=length(intersect(dept.1,dept.i))) ## count number of duplicates between two departments
rownames(val) <- paste(depts[i]) # attach department "i" name
intval <- rbind(intval,val) ## attach to empty dataframe
}
intval2[,j] <- intval ## attach completed row into empty dataframe
colnames(intval2)[j] <- paste(depts[j]) ##attach department "j" name
}
length(depts)
depts <- unique(df$Division.combined)
## empty data frames to load correlation values into
intval2 <- data.frame(matrix(ncol=length(depts),nrow=length(depts)))
for(j in 1:length(depts)){
intval <- data.frame() ## empty row dataframe
for(i in 1:length(depts)){
dept.1 <- subset(df, department==depts[j], select=c("If","Then.simplified")) ## select risks from department "j"
dept.1 <- paste(dept.1$If,dept.1$Then.simplified) ## combine into 1 column
dept.i <- subset(df, department==depts[i], select=c("If","Then.simplified")) ## select risks from department "i"
dept.i <- paste(dept.i$If,dept.i$Then.simplified) ## combine into 1 column
val <- data.frame(dept=length(intersect(dept.1,dept.i))) ## count number of duplicates between two departments
rownames(val) <- paste(depts[i]) # attach department "i" name
intval <- rbind(intval,val) ## attach to empty dataframe
}
intval2[,j] <- intval ## attach completed row into empty dataframe
colnames(intval2)[j] <- paste(depts[j]) ##attach department "j" name
}
intval2[,"dept1"] <- colnames(intval2)
cordata <- gather(intval2, dept2, value, 1:(ncol(intval2)-1))
ggplot(data = cordata, aes(x=dept1, y=dept2, fill=value)) +
geom_tile()
cordata
max(cordata$value)
intval2
depts <- unique(df$Division.combined)
## empty data frames to load correlation values into
intval2 <- data.frame(matrix(ncol=length(depts),nrow=length(depts)))
for(j in 1:length(depts)){
intval <- data.frame() ## empty row dataframe
for(i in 1:length(depts)){
dept.1 <- subset(df, Division.combined==depts[j], select=c("If","Then.simplified")) ## select risks from department "j"
dept.1 <- paste(dept.1$If,dept.1$Then.simplified) ## combine into 1 column
dept.i <- subset(df, Division.combined==depts[i], select=c("If","Then.simplified")) ## select risks from department "i"
dept.i <- paste(dept.i$If,dept.i$Then.simplified) ## combine into 1 column
val <- data.frame(dept=length(intersect(dept.1,dept.i))) ## count number of duplicates between two departments
rownames(val) <- paste(depts[i]) # attach department "i" name
intval <- rbind(intval,val) ## attach to empty dataframe
}
intval2[,j] <- intval ## attach completed row into empty dataframe
colnames(intval2)[j] <- paste(depts[j]) ##attach department "j" name
}
intval2[,"dept1"] <- colnames(intval2)
cordata <- gather(intval2, dept2, value, 1:(ncol(intval2)-1))
ggplot(data = cordata, aes(x=dept1, y=dept2, fill=value)) +
geom_tile()
ggplot(data = cordata, aes(x=dept1, y=dept2, fill=value)) +
geom_tile()+
scale_fill_gradient(low = "white", high = "red")
plot(data = cordata, aes(x=dept1, y=dept2, fill=value)) +
geom_tile()+
scale_fill_gradient(low = "white", high = "red") + ylab("") + xlab("")+ theme(axis.text.x = element_text(angle = 90, hjust = 1))
ggplot(data = cordata, aes(x=dept1, y=dept2, fill=value)) +
geom_tile()+
scale_fill_gradient(low = "white", high = "red") + ylab("") + xlab("")
ggplot(data = cordata, aes(x=dept1, y=dept2, fill=value)) +
geom_tile()+
scale_fill_gradient(low = "white", high = "red") + ylab("") + xlab("")+ theme(axis.text.x = element_text(angle = 90, hjust = 1))
cordata
=======
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
?downloadHandler
foxie
runApp()
library(rsconnect)
deployApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
filedata
runApp()
runApp()
runApp()
runApp()
?downloadhander
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
?downloadButton
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
shiny::runApp()
runApp()
runApp()
?downloadHandler
runApp()
runApp()
runApp()
runApp()
paste0("ClimScan", Sys.Date(), ".csv", sep="")
runApp()
shiny::runApp()
downloadHandler
runApp()
runApp()
runApp()
library(rsconnect)
deployApp()
runApp()
devtools::install_github('hadley/ggplot2')
library(rsconnect)
deployApp()
options(shiny.fullstacktrace = TRUE)
runApp()
runApp()
runApp()
deployApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
deployApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
>>>>>>> 0759f57132b334decfa7efb50614d41d9b261c73
runApp()
